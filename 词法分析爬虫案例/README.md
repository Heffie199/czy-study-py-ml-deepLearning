#  chenzy python 2018-07-10 词法分析采集房产信息

#  需求分析：
    1、爬取海南房产网[http://www.home898.com]官网下,（三亚市）[http://sanya.home898.com/]下的（三亚热销楼盘）房产动态信息。
    2、如果匹配有违规信息才进行采集存储。

 
#### 一、普通采集
    执行普通采集，速度相对快，但精确度低，特别是特殊名词（如：违禁词（万能）、但是文中描述是：万能路563号），
    这样就不能算违规吧？这是地名，不过也没有《万能路563号》地名，只是举例子哈~
#### 二、分词采集
    1、执行分词采集，精确度高，jieba分词不准确可定制分词字符。可添加名词到 data_file 包下的 jieba_userdict.txt 文件。
    如：万能路563号，可能jieba分词不够准确，有可能是：万能、路、563号。具体看 jieba[https://github.com/fxsjy/jieba]

    2、提高相对速度，因为要清理内容（不想要的字符串）可添加字符串到：def_nlp_jieba 包下 def_jieba.py 里的 removeList

#  采集步骤：
    1、关键字匹配代码实现       【已完成-》2018-07-10】
    2、截图代码实现            【已完成-》2018-07-10】
    3、链接数据库代码实现       【已完成-》2018-07-10】
    4、执行采集逻辑：
        #  第一步：网站分析    【已完成-》2018-07-10】
        #  第二步：采集清洗    【已完成-》2018-07-11】
        #  第三步：数据存储    【已完成-》2018-07-11】
        #  第四步：数据展示    【已完成-》Javaweb】

# 更新日志：
    采集海南房产网三亚市信息;[2018-07-11上午]
    可拓展式删除逻辑;[2018-07-12上午]
    可拓展式截图逻辑;[2018-07-12上午]
    执行分页获取[2018-07-12下午]
    特殊说明：本程序可采集海南房产网下的各个城市楼盘动态信息;[2018-07-12上午]
    nlp jieba 分词处理[目的：处理特殊名词]
    添加模型，强制性添加关键词



#  仓库声明：
    本项目数据信息来源：海南房产网[http://www.home898.com]、如有违规请联系我、马上删除本库！

# 如果喜欢，支持一下哈
    Author: chenzhengyou
    mail: 649954910@qq.com

![](https://github.com/andyczy/czy-study-deepLearning/blob/master/vxz.jpg "有你的支持、我更加努力！")


